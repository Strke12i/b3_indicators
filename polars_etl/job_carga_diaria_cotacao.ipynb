{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL_Cotacoes_B3_Diario.ipynb\n",
    "\n",
    "import polars as pl\n",
    "import requests\n",
    "import zipfile\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "# Suppress insecure request warnings\n",
    "warnings.simplefilter('ignore', InsecureRequestWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração de logs\n",
    "def setup_logging():\n",
    "    \"\"\"Configura o sistema de logs padronizados.\"\"\"\n",
    "    log_dir = \"logs\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # Nome do arquivo de log com data atual\n",
    "    log_file = os.path.join(log_dir, f\"etl_cotacoes_b3_{datetime.now().strftime('%Y%m%d')}.log\")\n",
    "\n",
    "    # Configuração do logger\n",
    "    logger = logging.getLogger(\"ETL_Cotacoes_B3\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Handler para arquivo\n",
    "    file_handler = logging.FileHandler(log_file)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # Handler para console\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "\n",
    "    # Formato padronizado para os logs\n",
    "    log_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    file_handler.setFormatter(log_format)\n",
    "    console_handler.setFormatter(log_format)\n",
    "\n",
    "    # Adicionar handlers ao logger\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "# Inicializar logger\n",
    "logger = setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações de banco de dados\n",
    "DATABASE_CONFIG = {\n",
    "    \"host\": \"db\",\n",
    "    \"database\": \"meu_banco\",\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"admin_password\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# --- Definições de colunas, mercados, etc. ---\n",
    "FIELD_SIZES = {\n",
    "    'TIPO_DE_REGISTRO': 2, 'DATA_DO_PREGAO': 8, 'CODIGO_BDI': 2, 'CODIGO_DE_NEGOCIACAO': 12,\n",
    "    'TIPO_DE_MERCADO': 3, 'NOME_DA_EMPRESA': 12, 'ESPECIFICACAO_DO_PAPEL': 10,\n",
    "    'PRAZO_EM_DIAS_DO_MERCADO_A_TERMO': 3, 'MOEDA_DE_REFERENCIA': 4, 'PRECO_DE_ABERTURA': 13,\n",
    "    'PRECO_MAXIMO': 13, 'PRECO_MINIMO': 13, 'PRECO_MEDIO': 13, 'PRECO_ULTIMO_NEGOCIO': 13,\n",
    "    'PRECO_MELHOR_OFERTA_DE_COMPRA': 13, 'PRECO_MELHOR_OFERTA_DE_VENDAS': 13,\n",
    "    'NUMERO_DE_NEGOCIOS': 5, 'QUANTIDADE_NEGOCIADA': 18, 'VOLUME_TOTAL_NEGOCIADO': 18,\n",
    "    'PRECO_DE_EXERCICIO': 13, 'INDICADOR_DE_CORRECAO_DE_PRECOS': 1, 'DATA_DE_VENCIMENTO': 8,\n",
    "    'FATOR_DE_COTACAO': 7, 'PRECO_DE_EXERCICIO_EM_PONTOS': 13, 'CODIGO_ISIN': 12,\n",
    "    'NUMERO_DE_DISTRIBUICAO': 3\n",
    "}\n",
    "\n",
    "BASE_URL = \"https://bvmf.bmfbovespa.com.br/InstDados/SerHist/COTAHIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B3DailyETL:\n",
    "    \"\"\"Classe para ETL diário de cotações da B3.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa o ETL com data atual.\"\"\"\n",
    "        # Usar o dia anterior por padrão, já que os dados da B3 são disponibilizados no dia seguinte\n",
    "        self.target_date = datetime.now() - timedelta(days=1)\n",
    "        self.url_suffix = f\"_D{self.target_date.day:02d}{self.target_date.month:02d}{self.target_date.year}.ZIP\"\n",
    "        self.existing_tickers = set()\n",
    "        logger.info(f\"ETL inicializado para a data: {self.target_date.strftime('%d/%m/%Y')}\")\n",
    "\n",
    "    def get_existing_tickers(self):\n",
    "        \"\"\"Busca os tickers existentes no banco de dados.\"\"\"\n",
    "        conn = None\n",
    "        try:\n",
    "            logger.info(\"Buscando tickers existentes no banco de dados...\")\n",
    "            conn = psycopg2.connect(**DATABASE_CONFIG)\n",
    "            with conn.cursor() as cursor:\n",
    "                cursor.execute(\"SELECT codigo_isin FROM ticker\")\n",
    "                self.existing_tickers = set(row[0] for row in cursor.fetchall())\n",
    "            logger.info(f\"Encontrados {len(self.existing_tickers)} tickers no banco de dados.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao buscar tickers: {e}\")\n",
    "            return False\n",
    "        finally:\n",
    "            if conn:\n",
    "                conn.close()\n",
    "\n",
    "    def download_and_extract(self):\n",
    "        \"\"\"Baixa e extrai o arquivo ZIP da B3 para o dia atual.\"\"\"\n",
    "        url = f\"{BASE_URL}{self.url_suffix}\"\n",
    "        tmp_zip_path = None\n",
    "        tmp_txt_path = None\n",
    "\n",
    "        try:\n",
    "            logger.info(f\"Baixando arquivo de {self.target_date.strftime('%d/%m/%Y')}: {url}\")\n",
    "            response = requests.get(url, verify=False, stream=True)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Salvar ZIP em arquivo temporário\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".zip\") as tmp_zip_file:\n",
    "                for chunk in response.iter_content(chunk_size=8192 * 16):\n",
    "                    tmp_zip_file.write(chunk)\n",
    "                tmp_zip_path = tmp_zip_file.name\n",
    "            logger.info(f\"Arquivo ZIP salvo em: {tmp_zip_path}\")\n",
    "\n",
    "            # Criar um arquivo temporário para o TXT\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".txt\") as tmp_txt_file:\n",
    "                tmp_txt_path = tmp_txt_file.name\n",
    "\n",
    "            # Fechar e remover o arquivo temporário vazio para evitar conflitos\n",
    "            os.remove(tmp_txt_path)\n",
    "\n",
    "            # Extrair TXT do ZIP\n",
    "            file_name_in_zip = self.url_suffix.replace('.ZIP', '.TXT')\n",
    "            file_name_in_zip = \"COTAHIST\" + file_name_in_zip\n",
    "\n",
    "            logger.info(f\"Extraindo arquivo {file_name_in_zip} do ZIP...\")\n",
    "            with zipfile.ZipFile(tmp_zip_path, 'r') as zf:\n",
    "                if file_name_in_zip not in zf.namelist():\n",
    "                    logger.error(f\"Arquivo {file_name_in_zip} não encontrado no ZIP\")\n",
    "                    logger.info(f\"Arquivos disponíveis no ZIP: {zf.namelist()}\")\n",
    "                    return None\n",
    "\n",
    "                # Extrair diretamente para o caminho temporário\n",
    "                with zf.open(file_name_in_zip) as source, open(tmp_txt_path, 'wb') as target:\n",
    "                    target.write(source.read())\n",
    "\n",
    "            logger.info(f\"Arquivo extraído com sucesso para: {tmp_txt_path}\")\n",
    "            return tmp_txt_path\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 404:\n",
    "                logger.warning(f\"Arquivo não encontrado para {self.target_date.strftime('%d/%m/%Y')}. \"\n",
    "                              f\"Possivelmente não houve pregão neste dia ou os dados ainda não foram publicados.\")\n",
    "            else:\n",
    "                logger.error(f\"Erro HTTP ao baixar arquivo: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao baixar/extrair arquivo: {e}\", exc_info=True)\n",
    "            return None\n",
    "        finally:\n",
    "            # Limpar arquivo ZIP temporário\n",
    "            if tmp_zip_path and os.path.exists(tmp_zip_path):\n",
    "                os.remove(tmp_zip_path)\n",
    "                logger.debug(f\"Arquivo ZIP temporário removido: {tmp_zip_path}\")\n",
    "\n",
    "    def process_file(self, file_path):\n",
    "        \"\"\"Processa o arquivo de cotações usando Polars.\"\"\"\n",
    "        logger.info(f\"Processando arquivo: {file_path}\")\n",
    "\n",
    "        try:\n",
    "            # Criar uma lista de posições de coluna baseada no FIELD_SIZES\n",
    "            column_positions = []\n",
    "            current_pos = 0\n",
    "            for col, width in FIELD_SIZES.items():\n",
    "                column_positions.append((current_pos, current_pos + width))\n",
    "                current_pos += width\n",
    "\n",
    "            # Filtrar apenas as colunas que precisamos\n",
    "            needed_columns = ['TIPO_DE_REGISTRO', 'DATA_DO_PREGAO', 'CODIGO_BDI', 'PRECO_DE_ABERTURA',\n",
    "                            'PRECO_ULTIMO_NEGOCIO', 'NUMERO_DE_NEGOCIOS', 'QUANTIDADE_NEGOCIADA',\n",
    "                            'VOLUME_TOTAL_NEGOCIADO', 'CODIGO_ISIN']\n",
    "\n",
    "            needed_positions = []\n",
    "            column_names = []\n",
    "            for i, col in enumerate(FIELD_SIZES.keys()):\n",
    "                if col in needed_columns:\n",
    "                    needed_positions.append(column_positions[i])\n",
    "                    column_names.append(col)\n",
    "\n",
    "            # Ler o arquivo usando Polars com leitura por colunas fixas\n",
    "            logger.info(\"Iniciando leitura do arquivo com Polars...\")\n",
    "            df = pl.read_csv(\n",
    "                file_path,\n",
    "                has_header=False,\n",
    "                skip_rows=1,\n",
    "                encoding='latin1',\n",
    "                separator='\\n',  # Cada linha é um registro\n",
    "                columns=[0],     # Lê apenas a primeira coluna que contém toda a linha\n",
    "                new_columns=[\"line\"]  # Renomeia para \"line\"\n",
    "            ).lazy()\n",
    "\n",
    "            # Extrair as colunas necessárias da linha usando expressões\n",
    "            for i, (col_name, (start, end)) in enumerate(zip(column_names, needed_positions)):\n",
    "                df = df.with_columns([\n",
    "                    pl.col(\"line\").str.slice(start, end - start).alias(col_name)\n",
    "                ])\n",
    "\n",
    "            # Filtrar linhas que não são trailer (TIPO_DE_REGISTRO != '99')\n",
    "            df = df.filter(pl.col(\"TIPO_DE_REGISTRO\") != \"99\")\n",
    "\n",
    "            # Filtrar por CODIGO_BDI == \"02\" (LOTE_PADRAO)\n",
    "            df = df.filter(pl.col(\"CODIGO_BDI\") == \"02\")\n",
    "\n",
    "            # Converter tipos de dados\n",
    "            df = df.with_columns([\n",
    "                # Converter datas\n",
    "                pl.col(\"DATA_DO_PREGAO\").str.to_date(\"%Y%m%d\").alias(\"data_pregao\"),\n",
    "\n",
    "                # Converter valores numéricos\n",
    "                (pl.col(\"PRECO_DE_ABERTURA\").cast(pl.Float64) / 100).alias(\"abertura\"),\n",
    "                (pl.col(\"PRECO_ULTIMO_NEGOCIO\").cast(pl.Float64) / 100).alias(\"fechamento\"),\n",
    "                pl.col(\"NUMERO_DE_NEGOCIOS\").cast(pl.Int64).alias(\"numero_de_negocios\"),\n",
    "                pl.col(\"QUANTIDADE_NEGOCIADA\").cast(pl.Float64).alias(\"quantidade_negociada\"),\n",
    "                pl.col(\"VOLUME_TOTAL_NEGOCIADO\").cast(pl.Float64).alias(\"volume_negociado\"),\n",
    "\n",
    "                # Manter CODIGO_ISIN como está\n",
    "                pl.col(\"CODIGO_ISIN\").alias(\"codigo_isin\")\n",
    "            ])\n",
    "\n",
    "            # Selecionar apenas as colunas finais e filtrar por tickers existentes\n",
    "            df = df.select([\n",
    "                \"codigo_isin\", \"data_pregao\", \"abertura\", \"fechamento\",\n",
    "                \"numero_de_negocios\", \"quantidade_negociada\", \"volume_negociado\"\n",
    "            ]).filter(\n",
    "                pl.col(\"codigo_isin\").is_in(list(self.existing_tickers))\n",
    "            )\n",
    "\n",
    "            # Executar o processamento e retornar o DataFrame materializado\n",
    "            result_df = df.collect()\n",
    "            logger.info(f\"Processamento concluído. Registros encontrados: {result_df.height}\")\n",
    "            return result_df\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erro ao processar arquivo: {e}\", exc_info=True)\n",
    "            return None\n",
    "\n",
    "    def insert_into_database(self, df, batch_size=10000):\n",
    "        \"\"\"Insere os dados processados no banco de dados.\"\"\"\n",
    "        if df is None or df.is_empty():\n",
    "            logger.warning(\"DataFrame vazio, nada a inserir.\")\n",
    "            return 0\n",
    "\n",
    "        conn = None\n",
    "        inserted = 0\n",
    "        try:\n",
    "            logger.info(\"Conectando ao banco de dados para inserção...\")\n",
    "            conn = psycopg2.connect(**DATABASE_CONFIG)\n",
    "            with conn.cursor() as cursor:\n",
    "                # Preparar dados para inserção\n",
    "                data = df.to_pandas().to_dict('records')\n",
    "                logger.info(f\"Preparando {len(data)} registros para inserção em lotes de {batch_size}\")\n",
    "\n",
    "                # Inserir em lotes para melhor performance\n",
    "                for i in range(0, len(data), batch_size):\n",
    "                    batch = data[i:i+batch_size]\n",
    "                    values = [(\n",
    "                        row['codigo_isin'],\n",
    "                        row['data_pregao'],\n",
    "                        row['abertura'],\n",
    "                        row['fechamento'],\n",
    "                        row['numero_de_negocios'],\n",
    "                        row['quantidade_negociada'],\n",
    "                        row['volume_negociado']\n",
    "                    ) for row in batch]\n",
    "\n",
    "                    # Usar execute_values para inserção em lote\n",
    "                    execute_values(\n",
    "                        cursor,\n",
    "                        \"\"\"\n",
    "                        INSERT INTO cotacao\n",
    "                        (codigo_isin, data_pregao, abertura, fechamento, numero_de_negocios,\n",
    "                        quantidade_negociada, volume_negociado)\n",
    "                        VALUES %s\n",
    "                        ON CONFLICT (codigo_isin, data_pregao) DO NOTHING\n",
    "                        \"\"\",\n",
    "                        values\n",
    "                    )\n",
    "                    logger.info(f\"Lote {i//batch_size + 1} inserido.\")\n",
    "\n",
    "                conn.commit()\n",
    "                inserted = len(data)\n",
    "                logger.info(f\"Inserção concluída. Total de registros processados: {inserted}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            if conn:\n",
    "                conn.rollback()\n",
    "            logger.error(f\"Erro ao inserir no banco de dados: {e}\", exc_info=True)\n",
    "        finally:\n",
    "            if conn:\n",
    "                conn.close()\n",
    "\n",
    "        return inserted\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Executa o ETL completo para o dia atual.\"\"\"\n",
    "        logger.info(\"=== Iniciando ETL diário de cotações B3 ===\")\n",
    "\n",
    "        # Etapa 1: Obter tickers existentes\n",
    "        if not self.get_existing_tickers():\n",
    "            logger.error(\"Falha ao obter tickers. Abortando ETL.\")\n",
    "            return False\n",
    "\n",
    "        if not self.existing_tickers:\n",
    "            logger.warning(\"Nenhum ticker encontrado no banco. Nenhuma cotação será inserida.\")\n",
    "            return False\n",
    "\n",
    "        # Etapa 2: Download e extração do arquivo\n",
    "        txt_path = self.download_and_extract()\n",
    "        if not txt_path:\n",
    "            logger.error(\"Falha ao baixar/extrair arquivo. Abortando ETL.\")\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            # Etapa 3: Processar arquivo\n",
    "            df = self.process_file(txt_path)\n",
    "            if df is None:\n",
    "                logger.error(\"Falha ao processar arquivo. Abortando ETL.\")\n",
    "                return False\n",
    "\n",
    "            if df.is_empty():\n",
    "                logger.warning(\"Nenhum registro válido encontrado após processamento.\")\n",
    "                return True  # Consideramos sucesso, apenas não há dados\n",
    "\n",
    "            # Etapa 4: Inserir no banco\n",
    "            inserted = self.insert_into_database(df)\n",
    "            if inserted > 0:\n",
    "                logger.info(f\"ETL concluído com sucesso. {inserted} registros processados.\")\n",
    "                return True\n",
    "            else:\n",
    "                logger.warning(\"Nenhum registro inserido no banco de dados.\")\n",
    "                return True  # Consideramos sucesso, apenas não há dados novos\n",
    "\n",
    "        \n",
    "        finally:\n",
    "            # Limpeza: remover arquivo temporário\n",
    "            if txt_path and os.path.exists(txt_path):\n",
    "                os.remove(txt_path)\n",
    "                logger.debug(f\"Arquivo temporário removido: {txt_path}\")\n",
    "\n",
    "        logger.info(\"=== ETL diário de cotações B3 finalizado ===\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Executar o ETL\n",
    "if __name__ == \"__main__\":\n",
    "    etl = B3DailyETL()\n",
    "    success = etl.run()\n",
    "    exit_code = 0 if success else 1\n",
    "    logger.info(f\"Programa finalizado com código de saída: {exit_code}\")\n",
    "    exit(exit_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
